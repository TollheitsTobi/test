{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_env_data(n):\n",
    "    env = gym.make(\"ALE/Freeway-v5\", render_mode=\"rgb_array\", obs_type=\"ram\", difficulty=1, mode=7)\n",
    "    observation = env.reset()\n",
    "\n",
    "    df = pd.DataFrame([observation])\n",
    "    # Actions: 0: nichts, 1: up, 2: down\n",
    "\n",
    "    actions = []\n",
    "\n",
    "    for i in range(n):\n",
    "        action = get_action_sample()\n",
    "        if i != 0:\n",
    "            df.loc[len(df)] = observation\n",
    "        actions.append(action)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            observation = env.reset()\n",
    "        if i % (n / 100) == 0:\n",
    "            print(f\"{(i / n) * 100}%\")\n",
    "    env.close()\n",
    "    df = df[[14, 103, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117]]\n",
    "    df[\"actions\"] = actions\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_action_sample():\n",
    "    x = random.randint(0, 101)\n",
    "    if x < 90:\n",
    "        return 1\n",
    "    if x < 97:\n",
    "        return 2\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(15, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 14),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        x = torch.FloatTensor(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_dfs(df):\n",
    "    df = pd.read_csv(\"gamedata/world_data_1.csv\")\n",
    "    start = df.head(1)\n",
    "    start.to_csv(\"gamedata/start.csv\")\n",
    "    df = df.tail(len(df) - 1)\n",
    "    df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "\n",
    "    dfY = df.copy()\n",
    "    dfY.drop([\"actions\"], axis=1, inplace=True)\n",
    "\n",
    "    dfY = dfY.drop(dfY.index[[0]])\n",
    "    df = df.drop(df.index[[len(df) - 1]])\n",
    "    dfY.index = df.index\n",
    "\n",
    "    df = df.reset_index()\n",
    "    dfY = df.reset_index()\n",
    "    return df, dfY"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def train(X, y, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for i in range(len(y)):\n",
    "        X_data = list(X.iloc[i])\n",
    "        y_data = list(y.iloc[i])\n",
    "        X_data = torch.tensor(X_data)\n",
    "        y_data = torch.tensor(y_data)\n",
    "        X_data.cuda()\n",
    "        y_data.cuda()\n",
    "\n",
    "        pred = model(X_data.float())\n",
    "\n",
    "        loss = loss_fn(pred.to(torch.float32), y_data.to(torch.float32))\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            #print(f\"loss: {loss_sum / 1000}\")\n",
    "            loss_sum = 0\n",
    "\n",
    "\n",
    "def test(X, y, model, loss_fn):\n",
    "    loss_sum = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(y)):\n",
    "            X_data = list(X.iloc[i])\n",
    "            y_data = list(y.iloc[i])\n",
    "            X_data = torch.tensor(X_data)\n",
    "            y_data = torch.tensor(y_data)\n",
    "\n",
    "            pred = model(X_data.float())\n",
    "            loss = loss_fn(pred, y_data)\n",
    "            loss_sum += loss\n",
    "\n",
    "    loss_sum /= len(y)\n",
    "\n",
    "    print(f\"Avg loss: {loss_sum}!\")\n",
    "    return loss_sum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def cv_model(X, y):\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "    model = Net()\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    last_test_avg = 10000\n",
    "    test_avg = 0\n",
    "    overfit = 0\n",
    "\n",
    "    epochs = 200\n",
    "\n",
    "    avg_losses = []\n",
    "\n",
    "    avg_losses.append(test(test_X, test_y, model, loss_fn))\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t + 1}-----------------------------\")\n",
    "        train(train_X, train_y, model, loss_fn, optimizer)\n",
    "        test_avg = test(test_X, test_y, model, loss_fn)\n",
    "        avg_losses.append(test_avg)\n",
    "        if test_avg > last_test_avg:\n",
    "            overfit += 1\n",
    "        else:\n",
    "            overfit = 0\n",
    "            last_test_avg = test_avg\n",
    "        if overfit >= 5:\n",
    "            print(f\"Epoche: {t}\")\n",
    "            break\n",
    "    torch.save(model, f\"game_model/game_model_1\")\n",
    "    return avg_losses\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def cv_model2(X, y):\n",
    "    k_fold = KFold(n_splits=5, shuffle=True, random_state=6988)\n",
    "    counter = 2\n",
    "    avg_all = []\n",
    "    for train_idx, test_idx in k_fold.split(X, y):\n",
    "        model = Net().cuda()\n",
    "        for layer in model.children():\n",
    "            if hasattr(layer, \"reset_parameters\"):\n",
    "                layer.reset_parameters()\n",
    "\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        print(f\"split: {counter}\")\n",
    "        train_X = df.loc[train_idx]\n",
    "        train_y = dfY.loc[train_idx]\n",
    "\n",
    "        test_X = df.loc[test_idx]\n",
    "        test_y = dfY.loc[test_idx]\n",
    "        last_test_avg = 0\n",
    "        test_avg = 0\n",
    "        overfit = 0\n",
    "\n",
    "        avg_losses = []\n",
    "\n",
    "        epochs = 100\n",
    "\n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t + 1}-----------------------------\")\n",
    "            train(train_X, train_y, model, loss_fn, optimizer)\n",
    "            test_avg = test(test_X, test_y, model, loss_fn)\n",
    "            avg_losses.append(test_avg)\n",
    "            if test_avg > last_test_avg:\n",
    "                overfit += 1\n",
    "            else:\n",
    "                overfit = 0\n",
    "                last_test_avg = test_avg\n",
    "            if overfit >= 5:\n",
    "                print(overfit)\n",
    "                print(f\"Epoche: {t}\")\n",
    "                break\n",
    "        avg_all.append(avg_losses)\n",
    "        break\n",
    "    return avg_all\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0.0%\n",
      "1.0%\n",
      "2.0%\n",
      "3.0%\n",
      "4.0%\n",
      "5.0%\n",
      "6.0%\n",
      "7.000000000000001%\n",
      "8.0%\n",
      "9.0%\n",
      "10.0%\n",
      "11.0%\n",
      "12.0%\n",
      "13.0%\n",
      "14.000000000000002%\n",
      "15.0%\n",
      "16.0%\n",
      "17.0%\n",
      "18.0%\n",
      "19.0%\n",
      "20.0%\n",
      "21.0%\n",
      "22.0%\n",
      "23.0%\n",
      "24.0%\n",
      "25.0%\n",
      "26.0%\n",
      "27.0%\n",
      "28.000000000000004%\n",
      "28.999999999999996%\n",
      "30.0%\n",
      "31.0%\n",
      "32.0%\n",
      "33.0%\n",
      "34.0%\n",
      "35.0%\n",
      "36.0%\n",
      "37.0%\n",
      "38.0%\n",
      "39.0%\n",
      "40.0%\n",
      "41.0%\n",
      "42.0%\n",
      "43.0%\n",
      "44.0%\n",
      "45.0%\n",
      "46.0%\n",
      "47.0%\n",
      "48.0%\n",
      "49.0%\n",
      "50.0%\n",
      "51.0%\n",
      "52.0%\n",
      "53.0%\n",
      "54.0%\n",
      "55.00000000000001%\n",
      "56.00000000000001%\n",
      "56.99999999999999%\n",
      "57.99999999999999%\n",
      "59.0%\n",
      "60.0%\n",
      "61.0%\n",
      "62.0%\n",
      "63.0%\n",
      "64.0%\n",
      "65.0%\n",
      "66.0%\n",
      "67.0%\n",
      "68.0%\n",
      "69.0%\n",
      "70.0%\n",
      "71.0%\n",
      "72.0%\n",
      "73.0%\n",
      "74.0%\n",
      "75.0%\n",
      "76.0%\n",
      "77.0%\n",
      "78.0%\n",
      "79.0%\n",
      "80.0%\n",
      "81.0%\n",
      "82.0%\n",
      "83.0%\n",
      "84.0%\n",
      "85.0%\n",
      "86.0%\n",
      "87.0%\n",
      "88.0%\n",
      "89.0%\n",
      "90.0%\n",
      "91.0%\n",
      "92.0%\n",
      "93.0%\n",
      "94.0%\n",
      "95.0%\n",
      "96.0%\n",
      "97.0%\n",
      "98.0%\n",
      "99.0%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x16 and 15x128)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [21], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m df \u001B[38;5;241m=\u001B[39m get_env_data(n)\n\u001B[0;32m      7\u001B[0m df, dfY \u001B[38;5;241m=\u001B[39m get_dfs(df)\n\u001B[1;32m----> 8\u001B[0m avg_losses \u001B[38;5;241m=\u001B[39m \u001B[43mcv_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdfY\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m x \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(avg_losses) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m200\u001B[39m:\n",
      "Cell \u001B[1;32mIn [18], line 20\u001B[0m, in \u001B[0;36mcv_model\u001B[1;34m(X, y)\u001B[0m\n\u001B[0;32m     16\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m200\u001B[39m\n\u001B[0;32m     18\u001B[0m avg_losses \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 20\u001B[0m avg_losses\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-----------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn [17], line 37\u001B[0m, in \u001B[0;36mtest\u001B[1;34m(X, y, model, loss_fn)\u001B[0m\n\u001B[0;32m     34\u001B[0m X_data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(X_data)\n\u001B[0;32m     35\u001B[0m y_data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(y_data)\n\u001B[1;32m---> 37\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(pred, y_data)\n\u001B[0;32m     39\u001B[0m loss_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn [5], line 18\u001B[0m, in \u001B[0;36mNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 18\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_relu_stack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mFloatTensor(x)\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1x16 and 15x128)"
     ]
    }
   ],
   "source": [
    "n_data = [1000, 2000, 5000, 10000, 20000]\n",
    "df_losses = pd.DataFrame()\n",
    "\n",
    "for n in n_data:\n",
    "    print(n)\n",
    "    df = get_env_data(n)\n",
    "    df, dfY = get_dfs(df)\n",
    "    avg_losses = cv_model(df, dfY)\n",
    "\n",
    "    x = []\n",
    "\n",
    "    while len(avg_losses) < 200:\n",
    "        avg_losses.append(avg_losses[len(avg_losses) - 1])\n",
    "    for i in avg_losses:\n",
    "        x.append(i.item())\n",
    "    df_losses[f\"{n}\"] = x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "           1000         2000         5000        10000        20000  \\\n0   7437.459473  7225.813965  7255.167969  7275.524414  7306.245117   \n1   3132.988770  2947.085693  2510.976074  2889.854980  3848.984619   \n2   2282.169189  2194.750977  2211.690674  2593.416504  3629.458984   \n3   1947.890625  1904.734863  1920.263428  1935.618164  3432.967773   \n4   1782.133789  1277.788086  1726.900146  1766.064819  3307.291016   \n5   1692.899414  1106.661743  1599.137939  1645.445923  2735.440918   \n6   1645.171265  1004.954773  1509.948853  1555.667358  2166.250244   \n7   1618.498779   947.637817  1448.989502  1492.518799  2076.009521   \n8   1602.042480   911.591309  1411.718750  1445.187622  2032.991211   \n9   1591.599731   886.964539  1386.872681  1411.676880  2008.097778   \n10  1584.578613   869.548523  1371.502319  1389.578613  1989.422974   \n11  1579.912354   857.219910  1360.679565  1373.274658  1979.207520   \n12  1576.521118   848.570618  1352.847534  1361.445190  1972.197144   \n13  1573.833252   842.347839  1347.162842  1352.837524  1967.306885   \n14  1571.995117   837.594116  1342.982910  1346.300415  1963.716309   \n15  1570.347656   834.123779  1339.685669  1341.225830  1961.149658   \n16  1569.215820   831.310730  1337.792236  1337.006592  1958.785156   \n17  1568.413696   829.028076  1336.085205  1334.044678  1956.636230   \n18  1567.637939   826.993225  1334.900146  1331.493408  1954.209961   \n19  1566.966309   826.231934  1333.200684  1328.200317  1951.695312   \n20  1566.871826   825.031982  1331.384277  1325.373535  1949.715942   \n21  1566.465454   823.642273  1329.773438  1323.201050  1947.783569   \n22  1192.034668   822.477661  1328.161743  1320.812012  1945.662231   \n23  1067.151123   821.416260  1326.635010  1318.889038  1943.552246   \n24  1044.541504   820.178040  1119.924316  1316.912231  1941.170654   \n25  1028.814941   819.002869   876.832031  1314.873169  1938.913574   \n26  1017.217285   817.892883   855.172363  1312.319092  1936.974365   \n27  1008.796570   816.709778   840.083435  1309.845337  1934.319336   \n28  1002.340637   815.703308   828.712830  1307.588501  1932.035522   \n29   997.804871   814.181030   819.588684  1305.474487  1929.560303   \n30   993.920227   812.840698   812.093384  1303.348755  1926.869385   \n31   990.565918   811.723022   806.362122  1301.408447  1924.216675   \n32   988.350647   810.406189   801.855408  1299.405762  1921.632446   \n33   987.010376   809.301514   797.823975  1297.280396  1918.968872   \n34   986.111084   807.964355   794.445251  1295.353394  1916.489258   \n35   984.907654   806.676941   791.402527  1293.541138  1914.160156   \n36   984.032654   805.329163   788.777649  1291.762451  1912.112549   \n37   983.011902   803.722107   786.010010  1289.981323  1910.099121   \n38   982.092346   802.422974   783.551270  1288.093018  1907.930176   \n39   980.904480   800.788330   781.168579  1286.399170  1906.178101   \n40   979.893127   799.751038   778.949158  1285.085571  1904.167603   \n41   978.390320   798.233521   776.706726  1283.488159  1902.287964   \n42   976.873108   796.907410   774.465698  1282.072021  1900.447998   \n43   975.237915   795.535156   772.391541  1280.495361  1898.901367   \n44   973.644226   794.435608   770.638611  1279.204590  1897.217773   \n45   971.933655   793.015808   768.645752  1278.216309  1895.887695   \n46   970.227966   791.719482   766.640808  1276.945923  1894.463135   \n47   968.547485   790.372131   764.597717  1275.747192  1893.244263   \n48   966.851074   789.106567   762.792908  1274.866943  1892.053101   \n49   965.046143   787.740723   760.995056  1273.458252  1890.802612   \n50   963.379272   786.848694   759.516663  1272.809082  1889.489990   \n\n          50000  \n0   7319.188965  \n1   2869.062500  \n2   2460.677490  \n3   1454.468140  \n4   1105.400879  \n5   1002.795410  \n6    943.669556  \n7    909.416382  \n8    888.576416  \n9    874.340149  \n10   863.828979  \n11   856.942139  \n12   851.105530  \n13   846.605103  \n14   843.187744  \n15   840.627258  \n16   838.784424  \n17   837.229553  \n18   836.062561  \n19   834.870483  \n20   834.075806  \n21   833.421631  \n22   832.669189  \n23   832.033020  \n24   831.418030  \n25   830.760010  \n26   830.230164  \n27   829.550537  \n28   828.731323  \n29   827.807739  \n30   827.072510  \n31   826.468506  \n32   825.794067  \n33   825.146973  \n34   824.255554  \n35   823.431885  \n36   822.681152  \n37   821.640259  \n38   820.691772  \n39   819.646667  \n40   818.570801  \n41   817.451355  \n42   816.343018  \n43   815.377808  \n44   814.182800  \n45   812.998230  \n46   811.742493  \n47   810.535522  \n48   809.169434  \n49   807.754395  \n50   806.467407  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1000</th>\n      <th>2000</th>\n      <th>5000</th>\n      <th>10000</th>\n      <th>20000</th>\n      <th>50000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7437.459473</td>\n      <td>7225.813965</td>\n      <td>7255.167969</td>\n      <td>7275.524414</td>\n      <td>7306.245117</td>\n      <td>7319.188965</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3132.988770</td>\n      <td>2947.085693</td>\n      <td>2510.976074</td>\n      <td>2889.854980</td>\n      <td>3848.984619</td>\n      <td>2869.062500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2282.169189</td>\n      <td>2194.750977</td>\n      <td>2211.690674</td>\n      <td>2593.416504</td>\n      <td>3629.458984</td>\n      <td>2460.677490</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1947.890625</td>\n      <td>1904.734863</td>\n      <td>1920.263428</td>\n      <td>1935.618164</td>\n      <td>3432.967773</td>\n      <td>1454.468140</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1782.133789</td>\n      <td>1277.788086</td>\n      <td>1726.900146</td>\n      <td>1766.064819</td>\n      <td>3307.291016</td>\n      <td>1105.400879</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1692.899414</td>\n      <td>1106.661743</td>\n      <td>1599.137939</td>\n      <td>1645.445923</td>\n      <td>2735.440918</td>\n      <td>1002.795410</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1645.171265</td>\n      <td>1004.954773</td>\n      <td>1509.948853</td>\n      <td>1555.667358</td>\n      <td>2166.250244</td>\n      <td>943.669556</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1618.498779</td>\n      <td>947.637817</td>\n      <td>1448.989502</td>\n      <td>1492.518799</td>\n      <td>2076.009521</td>\n      <td>909.416382</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1602.042480</td>\n      <td>911.591309</td>\n      <td>1411.718750</td>\n      <td>1445.187622</td>\n      <td>2032.991211</td>\n      <td>888.576416</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1591.599731</td>\n      <td>886.964539</td>\n      <td>1386.872681</td>\n      <td>1411.676880</td>\n      <td>2008.097778</td>\n      <td>874.340149</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1584.578613</td>\n      <td>869.548523</td>\n      <td>1371.502319</td>\n      <td>1389.578613</td>\n      <td>1989.422974</td>\n      <td>863.828979</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1579.912354</td>\n      <td>857.219910</td>\n      <td>1360.679565</td>\n      <td>1373.274658</td>\n      <td>1979.207520</td>\n      <td>856.942139</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1576.521118</td>\n      <td>848.570618</td>\n      <td>1352.847534</td>\n      <td>1361.445190</td>\n      <td>1972.197144</td>\n      <td>851.105530</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1573.833252</td>\n      <td>842.347839</td>\n      <td>1347.162842</td>\n      <td>1352.837524</td>\n      <td>1967.306885</td>\n      <td>846.605103</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1571.995117</td>\n      <td>837.594116</td>\n      <td>1342.982910</td>\n      <td>1346.300415</td>\n      <td>1963.716309</td>\n      <td>843.187744</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1570.347656</td>\n      <td>834.123779</td>\n      <td>1339.685669</td>\n      <td>1341.225830</td>\n      <td>1961.149658</td>\n      <td>840.627258</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1569.215820</td>\n      <td>831.310730</td>\n      <td>1337.792236</td>\n      <td>1337.006592</td>\n      <td>1958.785156</td>\n      <td>838.784424</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1568.413696</td>\n      <td>829.028076</td>\n      <td>1336.085205</td>\n      <td>1334.044678</td>\n      <td>1956.636230</td>\n      <td>837.229553</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1567.637939</td>\n      <td>826.993225</td>\n      <td>1334.900146</td>\n      <td>1331.493408</td>\n      <td>1954.209961</td>\n      <td>836.062561</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1566.966309</td>\n      <td>826.231934</td>\n      <td>1333.200684</td>\n      <td>1328.200317</td>\n      <td>1951.695312</td>\n      <td>834.870483</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1566.871826</td>\n      <td>825.031982</td>\n      <td>1331.384277</td>\n      <td>1325.373535</td>\n      <td>1949.715942</td>\n      <td>834.075806</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1566.465454</td>\n      <td>823.642273</td>\n      <td>1329.773438</td>\n      <td>1323.201050</td>\n      <td>1947.783569</td>\n      <td>833.421631</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1192.034668</td>\n      <td>822.477661</td>\n      <td>1328.161743</td>\n      <td>1320.812012</td>\n      <td>1945.662231</td>\n      <td>832.669189</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1067.151123</td>\n      <td>821.416260</td>\n      <td>1326.635010</td>\n      <td>1318.889038</td>\n      <td>1943.552246</td>\n      <td>832.033020</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1044.541504</td>\n      <td>820.178040</td>\n      <td>1119.924316</td>\n      <td>1316.912231</td>\n      <td>1941.170654</td>\n      <td>831.418030</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1028.814941</td>\n      <td>819.002869</td>\n      <td>876.832031</td>\n      <td>1314.873169</td>\n      <td>1938.913574</td>\n      <td>830.760010</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1017.217285</td>\n      <td>817.892883</td>\n      <td>855.172363</td>\n      <td>1312.319092</td>\n      <td>1936.974365</td>\n      <td>830.230164</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1008.796570</td>\n      <td>816.709778</td>\n      <td>840.083435</td>\n      <td>1309.845337</td>\n      <td>1934.319336</td>\n      <td>829.550537</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1002.340637</td>\n      <td>815.703308</td>\n      <td>828.712830</td>\n      <td>1307.588501</td>\n      <td>1932.035522</td>\n      <td>828.731323</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>997.804871</td>\n      <td>814.181030</td>\n      <td>819.588684</td>\n      <td>1305.474487</td>\n      <td>1929.560303</td>\n      <td>827.807739</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>993.920227</td>\n      <td>812.840698</td>\n      <td>812.093384</td>\n      <td>1303.348755</td>\n      <td>1926.869385</td>\n      <td>827.072510</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>990.565918</td>\n      <td>811.723022</td>\n      <td>806.362122</td>\n      <td>1301.408447</td>\n      <td>1924.216675</td>\n      <td>826.468506</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>988.350647</td>\n      <td>810.406189</td>\n      <td>801.855408</td>\n      <td>1299.405762</td>\n      <td>1921.632446</td>\n      <td>825.794067</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>987.010376</td>\n      <td>809.301514</td>\n      <td>797.823975</td>\n      <td>1297.280396</td>\n      <td>1918.968872</td>\n      <td>825.146973</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>986.111084</td>\n      <td>807.964355</td>\n      <td>794.445251</td>\n      <td>1295.353394</td>\n      <td>1916.489258</td>\n      <td>824.255554</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>984.907654</td>\n      <td>806.676941</td>\n      <td>791.402527</td>\n      <td>1293.541138</td>\n      <td>1914.160156</td>\n      <td>823.431885</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>984.032654</td>\n      <td>805.329163</td>\n      <td>788.777649</td>\n      <td>1291.762451</td>\n      <td>1912.112549</td>\n      <td>822.681152</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>983.011902</td>\n      <td>803.722107</td>\n      <td>786.010010</td>\n      <td>1289.981323</td>\n      <td>1910.099121</td>\n      <td>821.640259</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>982.092346</td>\n      <td>802.422974</td>\n      <td>783.551270</td>\n      <td>1288.093018</td>\n      <td>1907.930176</td>\n      <td>820.691772</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>980.904480</td>\n      <td>800.788330</td>\n      <td>781.168579</td>\n      <td>1286.399170</td>\n      <td>1906.178101</td>\n      <td>819.646667</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>979.893127</td>\n      <td>799.751038</td>\n      <td>778.949158</td>\n      <td>1285.085571</td>\n      <td>1904.167603</td>\n      <td>818.570801</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>978.390320</td>\n      <td>798.233521</td>\n      <td>776.706726</td>\n      <td>1283.488159</td>\n      <td>1902.287964</td>\n      <td>817.451355</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>976.873108</td>\n      <td>796.907410</td>\n      <td>774.465698</td>\n      <td>1282.072021</td>\n      <td>1900.447998</td>\n      <td>816.343018</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>975.237915</td>\n      <td>795.535156</td>\n      <td>772.391541</td>\n      <td>1280.495361</td>\n      <td>1898.901367</td>\n      <td>815.377808</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>973.644226</td>\n      <td>794.435608</td>\n      <td>770.638611</td>\n      <td>1279.204590</td>\n      <td>1897.217773</td>\n      <td>814.182800</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>971.933655</td>\n      <td>793.015808</td>\n      <td>768.645752</td>\n      <td>1278.216309</td>\n      <td>1895.887695</td>\n      <td>812.998230</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>970.227966</td>\n      <td>791.719482</td>\n      <td>766.640808</td>\n      <td>1276.945923</td>\n      <td>1894.463135</td>\n      <td>811.742493</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>968.547485</td>\n      <td>790.372131</td>\n      <td>764.597717</td>\n      <td>1275.747192</td>\n      <td>1893.244263</td>\n      <td>810.535522</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>966.851074</td>\n      <td>789.106567</td>\n      <td>762.792908</td>\n      <td>1274.866943</td>\n      <td>1892.053101</td>\n      <td>809.169434</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>965.046143</td>\n      <td>787.740723</td>\n      <td>760.995056</td>\n      <td>1273.458252</td>\n      <td>1890.802612</td>\n      <td>807.754395</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>963.379272</td>\n      <td>786.848694</td>\n      <td>759.516663</td>\n      <td>1272.809082</td>\n      <td>1889.489990</td>\n      <td>806.467407</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_losses.to_csv(\"gamedata/data_test_4.csv\")\n",
    "df_losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.state = torch.tensor(list(pd.read_csv(\"gamedata/start.csv\").drop([\"Unnamed: 0.1\", \"Unnamed: 0\"], axis=1).loc[0]))\n",
    "        self.pos = 6\n",
    "        self.max_pos = 6\n",
    "        self.done = False\n",
    "        self.score = 0\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=210, shape=(14,))\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = torch.tensor(list(pd.read_csv(\"gamedata/start.csv\").drop([\"Unnamed: 0.1\", \"Unnamed: 0\", \"actions\"], axis=1).loc[0]))\n",
    "        self.pos = 6\n",
    "        self.max_pos = 6\n",
    "        self.done = False\n",
    "        self.score = 0\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        self.state = self.state.tolist()\n",
    "        self.state.append(action)\n",
    "        obs = self.model.forward(torch.tensor(self.state))\n",
    "        self.pos = obs[0]\n",
    "        reward = 0\n",
    "        if self.pos > self.max_pos + 1:\n",
    "            reward += 1\n",
    "            self.max_pos = self.pos\n",
    "        if 90 <= obs[2] <= 100:\n",
    "            reward -= 1000\n",
    "        if  self.score != obs[1]:\n",
    "            self.score = obs[1]\n",
    "            reward += 100\n",
    "        return obs, reward, False, {}\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [241], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m env \u001B[38;5;241m=\u001B[39m CustomEnv(model)\n\u001B[0;32m      8\u001B[0m model \u001B[38;5;241m=\u001B[39m TRPO(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMlpPolicy\u001B[39m\u001B[38;5;124m\"\u001B[39m, env, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.99\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10_000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrpo_custom\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\sb3_contrib\\trpo\\trpo.py:421\u001B[0m, in \u001B[0;36mTRPO.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    408\u001B[0m     \u001B[38;5;28mself\u001B[39m: TRPOSelf,\n\u001B[0;32m    409\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    418\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    419\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m TRPOSelf:\n\u001B[1;32m--> 421\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_eval_episodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_eval_episodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_log_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_log_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:262\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    258\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_start(\u001B[38;5;28mlocals\u001B[39m(), \u001B[38;5;28mglobals\u001B[39m())\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m<\u001B[39m total_timesteps:\n\u001B[1;32m--> 262\u001B[0m     continue_training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrollout_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_rollout_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_steps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    264\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m continue_training \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m    265\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:181\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.collect_rollouts\u001B[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001B[0m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maction_space, gym\u001B[38;5;241m.\u001B[39mspaces\u001B[38;5;241m.\u001B[39mBox):\n\u001B[0;32m    179\u001B[0m     clipped_actions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mclip(actions, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39mlow, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39mhigh)\n\u001B[1;32m--> 181\u001B[0m new_obs, rewards, dones, infos \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclipped_actions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mnum_envs\n\u001B[0;32m    185\u001B[0m \u001B[38;5;66;03m# Give access to local variables\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:162\u001B[0m, in \u001B[0;36mVecEnv.step\u001B[1;34m(self, actions)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03mStep the environments with the given action\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \n\u001B[0;32m    158\u001B[0m \u001B[38;5;124;03m:param actions: the action\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;124;03m:return: observation, reward, done, information\u001B[39;00m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_async(actions)\n\u001B[1;32m--> 162\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:43\u001B[0m, in \u001B[0;36mDummyVecEnv.step_wait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep_wait\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m VecEnvStepReturn:\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m env_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_envs):\n\u001B[1;32m---> 43\u001B[0m         obs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_rews[env_idx], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_dones[env_idx], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_infos[env_idx] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menvs\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactions\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_dones[env_idx]:\n\u001B[0;32m     47\u001B[0m             \u001B[38;5;66;03m# save final observation where user can get it, then reset\u001B[39;00m\n\u001B[0;32m     48\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_infos[env_idx][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mterminal_observation\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m obs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001B[0m, in \u001B[0;36mMonitor.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneeds_reset:\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTried to step environment that needs reset\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 94\u001B[0m observation, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrewards\u001B[38;5;241m.\u001B[39mappend(reward)\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m done:\n",
      "Cell \u001B[1;32mIn [237], line 23\u001B[0m, in \u001B[0;36mCustomEnv.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mappend(action)\n\u001B[1;32m---> 23\u001B[0m obs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlong\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos \u001B[38;5;241m=\u001B[39m obs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     25\u001B[0m reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "Cell \u001B[1;32mIn [128], line 14\u001B[0m, in \u001B[0;36mNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 14\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_relu_stack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "from sb3_contrib import TRPO\n",
    "\n",
    "model = torch.load(\"game_model/game_model_1\")\n",
    "\n",
    "env = CustomEnv(model)\n",
    "model = TRPO(\"MlpPolicy\", env, gamma=0.99, verbose=1)\n",
    "model.learn(total_timesteps=10_000, log_interval=4)\n",
    "model.save(\"trpo_custom\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Int but found Float",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [264], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(x)\n\u001B[0;32m      7\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mtype(torch\u001B[38;5;241m.\u001B[39mIntTensor)\n\u001B[1;32m----> 9\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m x\n",
      "Cell \u001B[1;32mIn [128], line 14\u001B[0m, in \u001B[0;36mNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 14\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_relu_stack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\loool\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: expected scalar type Int but found Float"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"game_model/game_model_1\")\n",
    "x = torch.tensor(list(pd.read_csv(\"gamedata/start.csv\").drop([\"Unnamed: 0.1\", \"Unnamed: 0\", \"actions\"], axis=1).loc[0]))\n",
    "#model.forward(torch.tensor(x.tolist().append(2)))\n",
    "x = x.tolist()\n",
    "x.append(2)\n",
    "x = torch.tensor(x)\n",
    "x = x.type(torch.IntTensor)\n",
    "\n",
    "model.forward(x)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
