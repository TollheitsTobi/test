{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sb3_contrib import TRPO, RecurrentPPO, TQC\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class ClipReward(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.best_y = 6\n",
    "        self.score = 0\n",
    "        self.last_y = 6\n",
    "\n",
    "    def reward(self, reward):\n",
    "        ram = env.unwrapped.ale.getRAM()\n",
    "        reward = 0\n",
    "        '''\n",
    "        reward -= (1/ram[14]) * 40\n",
    "\n",
    "\n",
    "\n",
    "        if ram[103] > self.score:\n",
    "            self.score = ram[103]\n",
    "            reward += 1000\n",
    "        if ram[14] > self.best_y:\n",
    "            self.best_y = ram[14]\n",
    "            reward += 3\n",
    "        if self.last_y > ram[14]:\n",
    "            reward -= ram[14]'''\n",
    "        if 90 <= ram[106] <= 100:\n",
    "            reward -= 100\n",
    "        if 140 <= ram[106] <= 141:\n",
    "            reward += 10000\n",
    "        reward -= 100/ram[14]\n",
    "        reward += ram[14]\n",
    "        if ram[14] >= 172:\n",
    "            self.best_y = 6\n",
    "        return reward"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_action_sample():\n",
    "    x = random.randint(0, 101)\n",
    "    if x < 90:\n",
    "        return 1\n",
    "    if x < 97:\n",
    "        return 2\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "UnregisteredEnv",
     "evalue": "No registered env with id: ALE/Freeway-v5",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\gym\\envs\\registration.py:158\u001B[0m, in \u001B[0;36mEnvRegistry.spec\u001B[1;34m(self, path)\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv_specs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mid\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;66;03m# Parse the env name and check to see if it matches the non-version\u001B[39;00m\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;66;03m# part of a valid env (could also check the exact number here)\u001B[39;00m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'ALE/Freeway-v5'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mUnregisteredEnv\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m env \u001B[38;5;241m=\u001B[39m ClipReward(\u001B[43mgym\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mALE/Freeway-v5\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobs_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mram\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrender_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhuman\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdifficulty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m7\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      2\u001B[0m obs \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mreset()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1000\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\gym\\envs\\registration.py:235\u001B[0m, in \u001B[0;36mmake\u001B[1;34m(id, **kwargs)\u001B[0m\n\u001B[0;32m    234\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake\u001B[39m(\u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 235\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m registry\u001B[38;5;241m.\u001B[39mmake(\u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\gym\\envs\\registration.py:128\u001B[0m, in \u001B[0;36mEnvRegistry.make\u001B[1;34m(self, path, **kwargs)\u001B[0m\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    127\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMaking new env: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, path)\n\u001B[1;32m--> 128\u001B[0m spec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    129\u001B[0m env \u001B[38;5;241m=\u001B[39m spec\u001B[38;5;241m.\u001B[39mmake(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m env\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\gym\\envs\\registration.py:203\u001B[0m, in \u001B[0;36mEnvRegistry.spec\u001B[1;34m(self, path)\u001B[0m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mUnregisteredEnv(\n\u001B[0;32m    198\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mToytext environment \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m has been moved out of Gym. Install it via `pip install gym-legacy-toytext` and add `import gym_toytext` before using it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    199\u001B[0m             \u001B[38;5;28mid\u001B[39m\n\u001B[0;32m    200\u001B[0m         )\n\u001B[0;32m    201\u001B[0m     )\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 203\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mUnregisteredEnv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo registered env with id: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mid\u001B[39m))\n",
      "\u001B[1;31mUnregisteredEnv\u001B[0m: No registered env with id: ALE/Freeway-v5"
     ]
    }
   ],
   "source": [
    "env = ClipReward(gym.make(\"ALE/Freeway-v5\", obs_type=\"ram\", render_mode=\"human\", difficulty=1, mode=7))\n",
    "obs = env.reset()\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = get_action_sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #env.render()\n",
    "    #time.sleep(0.00001)\n",
    "    print(reward)\n",
    "    if done:\n",
    "        obs = env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to tensorlog\\TRPO_24\n"
     ]
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca25af382bcb4e569827bb87d4c88494"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 246  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 8    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 2.05e+03  |\n",
      "|    ep_rew_mean            | -1.22e+04 |\n",
      "| time/                     |           |\n",
      "|    fps                    | 243       |\n",
      "|    iterations             | 2         |\n",
      "|    time_elapsed           | 16        |\n",
      "|    total_timesteps        | 4096      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -0.000568 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.0056    |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 1         |\n",
      "|    policy_objective       | 0.0189    |\n",
      "|    value_loss             | 1.22e+04  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m TRPO(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMlpPolicy\u001B[39m\u001B[38;5;124m\"\u001B[39m, env, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.95\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, tensorboard_log\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorlog\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m#model = TRPO.load(\"trpo_1.zip\", env=env)\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mITERATIONS\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mSTEPS_PER_ITERATION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrpo_1.zip\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m model \u001B[38;5;241m=\u001B[39m TRPO\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrpo_1.zip\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\sb3_contrib\\trpo\\trpo.py:421\u001B[0m, in \u001B[0;36mTRPO.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    408\u001B[0m     \u001B[38;5;28mself\u001B[39m: TRPOSelf,\n\u001B[0;32m    409\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    418\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    419\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m TRPOSelf:\n\u001B[1;32m--> 421\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_eval_episodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_eval_episodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_log_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_log_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:262\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    258\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_start(\u001B[38;5;28mlocals\u001B[39m(), \u001B[38;5;28mglobals\u001B[39m())\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m<\u001B[39m total_timesteps:\n\u001B[1;32m--> 262\u001B[0m     continue_training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrollout_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_rollout_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_steps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    264\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m continue_training \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m    265\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:172\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.collect_rollouts\u001B[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001B[0m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m th\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m    170\u001B[0m     \u001B[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001B[39;00m\n\u001B[0;32m    171\u001B[0m     obs_tensor \u001B[38;5;241m=\u001B[39m obs_as_tensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_last_obs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 172\u001B[0m     actions, values, log_probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    173\u001B[0m actions \u001B[38;5;241m=\u001B[39m actions\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    175\u001B[0m \u001B[38;5;66;03m# Rescale and perform action\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\stable_baselines3\\common\\policies.py:587\u001B[0m, in \u001B[0;36mActorCriticPolicy.forward\u001B[1;34m(self, obs, deterministic)\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[38;5;66;03m# Preprocess the observation if needed\u001B[39;00m\n\u001B[0;32m    586\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mextract_features(obs)\n\u001B[1;32m--> 587\u001B[0m latent_pi, latent_vf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    588\u001B[0m \u001B[38;5;66;03m# Evaluate the values for the given observations\u001B[39;00m\n\u001B[0;32m    589\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue_net(latent_vf)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:230\u001B[0m, in \u001B[0;36mMlpExtractor.forward\u001B[1;34m(self, features)\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    226\u001B[0m \u001B[38;5;124;03m:return: latent_policy, latent_value of the specified network.\u001B[39;00m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;124;03m    If all layers are shared, then ``latent_policy == latent_value``\u001B[39;00m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    229\u001B[0m shared_latent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_net(features)\n\u001B[1;32m--> 230\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolicy_net\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshared_latent\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue_net(shared_latent)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ITERATIONS = 2000\n",
    "STEPS_PER_ITERATION = 2048\n",
    "\n",
    "env = ClipReward(gym.make(\"ALE/Freeway-v5\", obs_type=\"ram\", difficulty=1, mode=3))\n",
    "obs = env.reset()\n",
    "\n",
    "model = TRPO(\"MlpPolicy\", env, gamma=0.95, verbose=1, tensorboard_log=\"tensorlog\")\n",
    "#model = TRPO.load(\"trpo_1.zip\", env=env)\n",
    "model.learn(total_timesteps=ITERATIONS*STEPS_PER_ITERATION, log_interval=1)\n",
    "model.save(\"trpo_1.zip\")\n",
    "\n",
    "model = TRPO.load(\"trpo_1.zip\")\n",
    "\n",
    "env = ClipReward(gym.make(\"ALE/Freeway-v5\", render_mode=\"human\", obs_type=\"ram\", difficulty=1, mode=3))\n",
    "obs = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #env.render()\n",
    "    #time.sleep(0.00001)\n",
    "    print(reward)\n",
    "    if done:\n",
    "        obs = env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "6.857142857142857\n",
      "0.0\n",
      "0.0\n",
      "-10.666666666666668\n",
      "0.0\n",
      "6.857142857142857\n",
      "6.857142857142857\n",
      "0.0\n",
      "6.857142857142857\n",
      "12.444444444444445\n",
      "12.444444444444445\n",
      "17.454545454545453\n",
      "22.153846153846153\n",
      "26.666666666666668\n",
      "31.058823529411764\n",
      "35.368421052631575\n",
      "39.61904761904762\n",
      "43.82608695652174\n",
      "48.0\n",
      "52.148148148148145\n",
      "56.275862068965516\n",
      "60.38709677419355\n",
      "64.48484848484848\n",
      "68.57142857142857\n",
      "72.64864864864865\n",
      "76.71794871794872\n",
      "80.78048780487805\n",
      "84.83720930232558\n",
      "88.88888888888889\n",
      "92.93617021276596\n",
      "96.9795918367347\n",
      "101.01960784313725\n",
      "105.05660377358491\n",
      "109.0909090909091\n",
      "113.12280701754386\n",
      "117.15254237288136\n",
      "121.18032786885246\n",
      "125.2063492063492\n",
      "129.23076923076923\n",
      "133.2537313432836\n",
      "137.2753623188406\n",
      "141.29577464788733\n",
      "145.31506849315068\n",
      "149.33333333333334\n",
      "153.35064935064935\n",
      "157.36708860759492\n",
      "161.3827160493827\n",
      "165.3975903614458\n",
      "169.41176470588235\n",
      "173.42528735632183\n",
      "-10.666666666666668\n",
      "9989.333333333334\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "0.0\n",
      "6.857142857142857\n",
      "6.857142857142857\n",
      "6.857142857142857\n",
      "12.444444444444445\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "0.0\n",
      "6.857142857142857\n",
      "12.444444444444445\n",
      "17.454545454545453\n",
      "22.153846153846153\n",
      "26.666666666666668\n",
      "31.058823529411764\n",
      "35.368421052631575\n",
      "39.61904761904762\n",
      "43.82608695652174\n",
      "48.0\n",
      "52.148148148148145\n",
      "48.0\n",
      "52.148148148148145\n",
      "56.275862068965516\n",
      "60.38709677419355\n",
      "64.48484848484848\n",
      "68.57142857142857\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-2.1111111111111107\n",
      "5.3076923076923075\n",
      "11.117647058823529\n",
      "16.238095238095237\n",
      "21.0\n",
      "25.551724137931036\n",
      "29.96969696969697\n",
      "34.2972972972973\n",
      "38.5609756097561\n",
      "42.77777777777778\n",
      "46.95918367346939\n",
      "51.113207547169814\n",
      "55.24561403508772\n",
      "59.36065573770492\n",
      "63.46153846153846\n",
      "67.55072463768116\n",
      "71.63013698630137\n",
      "75.7012987012987\n",
      "79.76543209876543\n",
      "83.82352941176471\n",
      "87.87640449438203\n",
      "91.9247311827957\n",
      "95.96907216494846\n",
      "100.00990099009901\n",
      "104.04761904761905\n",
      "108.08256880733946\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "0.0\n",
      "6.857142857142857\n",
      "12.444444444444445\n",
      "17.454545454545453\n",
      "22.153846153846153\n",
      "26.666666666666668\n",
      "31.058823529411764\n",
      "35.368421052631575\n",
      "39.61904761904762\n",
      "43.82608695652174\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "0.0\n",
      "6.857142857142857\n",
      "12.444444444444445\n",
      "17.454545454545453\n",
      "18.652173913043477\n",
      "23.296296296296298\n",
      "27.774193548387096\n",
      "32.142857142857146\n",
      "36.43589743589744\n",
      "40.674418604651166\n",
      "44.87234042553192\n",
      "49.03921568627451\n",
      "53.18181818181818\n",
      "57.30508474576271\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-4.5\n",
      "3.666666666666666\n",
      "9.75\n",
      "15.0\n",
      "19.833333333333332\n",
      "24.428571428571427\n",
      "28.875\n",
      "33.22222222222222\n",
      "37.5\n",
      "41.72727272727273\n",
      "45.916666666666664\n",
      "50.07692307692308\n",
      "50.07692307692308\n",
      "46.95918367346939\n",
      "51.113207547169814\n",
      "55.24561403508772\n",
      "59.36065573770492\n",
      "63.46153846153846\n",
      "67.55072463768116\n",
      "71.63013698630137\n",
      "75.7012987012987\n",
      "79.76543209876543\n",
      "83.82352941176471\n",
      "87.87640449438203\n",
      "91.9247311827957\n",
      "95.96907216494846\n",
      "100.00990099009901\n",
      "104.04761904761905\n",
      "108.08256880733946\n",
      "112.11504424778761\n",
      "116.14529914529915\n",
      "120.17355371900827\n",
      "124.2\n",
      "128.2248062015504\n",
      "132.24812030075188\n",
      "136.27007299270073\n",
      "140.29078014184398\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-4.5\n",
      "3.666666666666666\n",
      "9.75\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-2.1111111111111107\n",
      "5.3076923076923075\n",
      "11.117647058823529\n",
      "16.238095238095237\n",
      "21.0\n",
      "25.551724137931036\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-2.1111111111111107\n",
      "5.3076923076923075\n",
      "11.117647058823529\n",
      "16.238095238095237\n",
      "21.0\n",
      "25.551724137931036\n",
      "29.96969696969697\n",
      "34.2972972972973\n",
      "38.5609756097561\n",
      "42.77777777777778\n",
      "46.95918367346939\n",
      "51.113207547169814\n",
      "55.24561403508772\n",
      "59.36065573770492\n",
      "59.36065573770492\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "0.0\n",
      "6.857142857142857\n",
      "12.444444444444445\n",
      "17.454545454545453\n",
      "22.153846153846153\n",
      "26.666666666666668\n",
      "31.058823529411764\n",
      "35.368421052631575\n",
      "39.61904761904762\n",
      "43.82608695652174\n",
      "48.0\n",
      "52.148148148148145\n",
      "56.275862068965516\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-4.5\n",
      "3.666666666666666\n",
      "9.75\n",
      "15.0\n",
      "19.833333333333332\n",
      "24.428571428571427\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-4.5\n",
      "3.666666666666666\n",
      "9.75\n",
      "15.0\n",
      "19.833333333333332\n",
      "24.428571428571427\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-4.5\n",
      "3.666666666666666\n",
      "9.75\n",
      "15.0\n",
      "19.833333333333332\n",
      "24.428571428571427\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-4.5\n",
      "3.666666666666666\n",
      "9.75\n",
      "3.666666666666666\n",
      "9.75\n",
      "15.0\n",
      "19.833333333333332\n",
      "24.428571428571427\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-4.5\n",
      "3.666666666666666\n",
      "9.75\n",
      "15.0\n",
      "19.833333333333332\n",
      "24.428571428571427\n",
      "28.875\n",
      "33.22222222222222\n",
      "37.5\n",
      "41.72727272727273\n",
      "45.916666666666664\n",
      "50.07692307692308\n",
      "54.214285714285715\n",
      "58.333333333333336\n",
      "62.4375\n",
      "66.52941176470588\n",
      "70.61111111111111\n",
      "74.6842105263158\n",
      "-110.66666666666667\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n",
      "-10.666666666666668\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1000\u001B[39m):\n\u001B[0;32m      6\u001B[0m     action, _states \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(obs, deterministic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 7\u001B[0m     obs, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m#env.render()\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m#time.sleep(0.00001)\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28mprint\u001B[39m(reward)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\gym\\core.py:336\u001B[0m, in \u001B[0;36mRewardWrapper.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[1;32m--> 336\u001B[0m     observation, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    337\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m observation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreward(reward), done, info\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\gym\\wrappers\\time_limit.py:18\u001B[0m, in \u001B[0;36mTimeLimit.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[0;32m     16\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     17\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot call env.step() before calling reset()\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 18\u001B[0m     observation, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_episode_steps:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pseminar\\lib\\site-packages\\gym\\envs\\atari\\environment.py:222\u001B[0m, in \u001B[0;36mAtariEnv.step\u001B[1;34m(self, action_ind)\u001B[0m\n\u001B[0;32m    220\u001B[0m reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(frameskip):\n\u001B[1;32m--> 222\u001B[0m     reward \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39male\u001B[38;5;241m.\u001B[39mact(action)\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_obs(), reward, terminal, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_info()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = TRPO.load(\"trpo_1.zip\")\n",
    "\n",
    "env = ClipReward(gym.make(\"ALE/Freeway-v5\", render_mode=\"human\", obs_type=\"ram\", difficulty=1, mode=7))\n",
    "obs = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #env.render()\n",
    "    #time.sleep(0.00001)\n",
    "    print(reward)\n",
    "    if done:\n",
    "        obs = env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TRPO.load(\"trpo_3.zip\")\n",
    "\n",
    "env = ClipReward(gym.make(\"ALE/Freeway-v5\", render_mode=\"human\", obs_type=\"ram\", difficulty=1, mode=0))\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #env.render()\n",
    "    #time.sleep(0.00001)\n",
    "    print(reward)\n",
    "    if done:\n",
    "        obs = env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "\n",
    "env = Monitor(ClipReward(gym.make(\"ALE/Freeway-v5\", render_mode=\"human\", obs_type=\"ram\", difficulty=1, mode=0)), './video', force=True)\n",
    "state = env.reset()\n",
    "\n",
    "model = TRPO.load(\"trpo_1.zip\", env=env)\n",
    "\n",
    "done = False\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(state, deterministic=True)\n",
    "    state, reward, done, info = env.step(action)\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
